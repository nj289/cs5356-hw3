<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width">
    <link rel="stylesheet" href="styles.css">
    <title>Trust & Safety Basics</title>
</head>
<body>
    <header>
        <h1>Trust & Safety Basics</h1>
    </header>
    <main>
        <section>
            <h3>This is a webpage about frameworks and tools for enforcing Trust and Safety policies in digital spaces. </h3>
            <figure>
                <img src="ts.png" alt="Trust & Safety Image">
            </figure>
        </section>
        <section>
            <p>The above image was generated with ChatGPT. Instead of creating a bio for an individual, I'm centering this webpage on Trust & Safety (T&S) because
                I'm taking a fascinating course about it and interviewing for T&S internships at the moment.
                All of us interact with T&S features and interventions in our use of digital platforms like Instagram, X, Google,
                and even apps like Strava or Spotify. These serve a number of purposes, such as ensuring that users do not encounter
                violative content (e.g., gore, violence, sexually explicit material, etc. that they wish not to see), do not fall
                prey to scams and fraud, and do not enable serious offline harms. Without them, much of the internet could be a dark,
                predatory space. Click each box below to learn more about the AIM (Anticipate, Incentivize, Moderate) framework for T&S interventions:
            </p>
        </section>
        <section class="boxes">
            <div class="box">
                <details>
                    <summary><h4>Anticipate Harm: </h4></summary>
                    <ul>
                        <li>Create a risk assessment for a new product or feature.</li>
                        <li>Study rising dangerous trends on similar products and in society as a whole.</li>
                    </ul>
                </details>
            </div>
            <div class="box">
                <details>
                <summary><h4>Incentivize Safe Experiences: </h4></summary>
                <ul>
                    <li>Build classifiers and other mechanisms to downrank harmful content.</li>
                    <li>Design, test, and launch interventions that might reduce the likelihood of users engaging in harmful behavior.</li>
                </ul>
                </details>
            </div>
            <div class="box">
                <details>
                    <summary><h4>Moderate Harmful Content: </h4></summary>
                <ul>
                    <li>Define unacceptable content, user, and product behaviors.</li>
                    <li>Respond to user reports and mandated takedown requests.</li>
                </ul>
            </details>
            </div>
        </section>

        <section class="profanity-checker">
            <h3>Test a Trust & Safety tool for yourself. This profanity checker automatically censors any profane words that it detects. Such tools
                may be useful for digital spaces intended for professional use or children's use.
            </h3>
            <input type="text" id="userInput" placeholder="Enter text to check for profanity">
            <button onclick="checkProfanity()">Check</button>
            <p id="result"></p>
            </input>
        </section>

        <script> // used chatGPT for assistance on this complex script function writing
            function checkProfanity() {
                const userText = document.getElementById("userInput").value;
                const apiUrl = `https://www.purgomalum.com/service/json?text=${encodeURIComponent(userText)}`;
        
                fetch(apiUrl)
                    .then(response => response.json())
                    .then(data => {
                        if (data && data.result) {
                            if (data.result === userText) {
                                document.getElementById("result").textContent = "No profanity found.";
                            } else {
                                document.getElementById("result").textContent = `Filtered text: ${partiallyCensor(userText, data.result)}`;
                            }
                        } else {
                            document.getElementById("result").textContent = "Error: Invalid response from API.";
                        }
                    })
                    .catch(error => {
                        console.error("Error fetching data:", error);
                        document.getElementById("result").textContent = "Error fetching profanity check.";
                    });
            }
        
            function partiallyCensor(original, filtered) {
                let originalWords = original.split(" ");
                let filteredWords = filtered.split(" ");
        
                return filteredWords.map((word, index) => {
                    if (word !== originalWords[index]) {
                        return censorWord(originalWords[index]);
                    }
                    return word;
                }).join(" ");
            }
        
            function censorWord(word) {
                if (word.length <= 2) return word;
                return word[0] + "*".repeat(word.length - 2) + word[word.length - 1];
            }
        </script>

    </main>
    <footer>
        <p>&#169; 2025 Trust & Safety Basics </p>
    </footer>
</body>
</html>